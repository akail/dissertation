\section{Literature Review}
\label{sec:literature_review}
\subsection{Quality Assurance in Atmospheric Sciences}

Quality Assurance in the atmospheric sciences,as defined by Zahumensky \cite{zahumenskyGuidelinesQualityControl2004}, is the systematic implementation of a plan to fulfill the requirements for quality.  Those primary requirements are to ensure the "data are consistent, meets the data quality objectives, and can be fully described in its methodology.  Most weather organizations, including the World Meteorological Organization \cite{zahumenskyGuidelinesQualityControl2004}, the \gls{nws}  \cite{northropQUALITYASSURANCEPROGRAM2019}, several National Laboratories \cite{SRNLTR202000197Pdf}, as well as under the regulatory authority of the US \gls{epa} \cite{ElectronicCodeFederal} and US \gls{nrc} \cite{ML070630021Pdf}.

Current standard practice at these organizations use a combination of statistical techniques and rules to managed quality control.  This includes sensor calibration, automated checks and manual inspection \cite{graybealComplexQualityAssurance2004}.  The automated portion of the QA process is most relevant for the work here and most work has been focused on the refinement of statistical methods.  These methods look for statistical outliers in the high-frequency sample streams, and using the aggregate results to determine quality at that point in time \cite{campbellQuantityNothingQuality2013}.  The rules method, or more commonly called a range check, is also used as it is easy to implement and can verify several inconsistencies in the data.  For instance, relative humidity readings should always be between 0 and 100\%, rainfall gauges should not read negative values, and windspeed should be non-negative as well \cite{hillakerDailyClimateData2009} \cite{fiebrichQualityAssuranceProcedures2010}.

\subsection{Anomaly Detection in Machine Learning}

Need to distinguish between general AI anomaly detection methods and what meteorologists use

General anomaly detection looks for patterns in data that do not conform to the expected normal behavior of the data.  This pattern detection can be broken down into three types \cite{chandolaAnomalyDetectionSurvey}. The first is Point Anomalies, or a single point which does not match temporally or spatially the pattern in the surrounding data.  Another type of anomaly are contextual anomalies, which depending on the surrounding context of data, may or may not be an anomaly.  The final anomaly is collective anomalies, which is a collection of related anomalies.  While this may typically be seen as consecutive data in a time series, there may be anomaly collections which span data types and sources. Important to the work here is the development of context aware methods which have been developed for multi-data type problems \cite{branisavljevicImprovedRealtimeData2011}.

There are typically 3 types of methods, supervised learning, unsupervised learning, semi-supervised learning.  Encompassing each of these is the recent advance in deep learning techniques which leverage neural networks and massive amounts of data to generate their inference engines.


\subsubsection{Supervised Machine Learning}


Supervised machine learning is the process of mapping and input to an output which has been determined through a series of examples.  In anomaly detection, this is typically a classification problem rather than a regression problem \cite{chandolaAnomalyDetectionSurvey}. Supervised techniques have fallen out of use for anomaly detection due to requirement for labeled data. It is usually much easier to use unsupervised or semi-supervised techniques.  In situations where labeled data is available though, supervised techniques tend to be more performant, especially when combined with active learning to identify new types of anomalies \cite{goernitzSupervisedAnomalyDetection2013}.

 
\subsubsection{Unsupervised Machine Learning}

The most common method in machine learning is unsupervised, which can be broken down into a single class, or multi-class.  As mentioned previously, unsupervised machine learning provides many advantages over its labeled counterpart as it requires none of the data to be labeled before hand \cite{chandolaAnomalyDetectionSurvey}.  This lends itself to be highly adaptable to many data types. There are multiple types of algorithms which can be used.  There are clustering algorithms such as K-Nearest neighbors, k-means, and DB-SCAN \cite{xiaoweixuDistributionbasedClusteringAlgorithm1998}, which will group points together in clusters.  When applied to anomaly detection, these clusters can be used to identify outliers which deviate from the main cluster.  One distinct disadvantage of this technique is determining the optimal parameters, such as the 'k' parameters in KNN, which determines how many clusters will be generated.

\subsubsection{Semi-Supervised Machine Learning}

The term semi-supervised learning is a special case of supervised learning which has been developed in recent years.  It tackles a problem in anomaly detection in which there is a lack “of large labelled data and the limited number of anomalous samples.” By only training on good data sets, we reduce the amount of time required searching and labeling the different types of “bad” or defective data. There are only a few techniques currently which can make use of this method, Generative Adversarial Networks and Auto-encoders, both of which are types of Neural networks commonly seen in deep learning. 

The Auto-encoder method developed  Minhas Et Al \cite{minhasSemisupervisedAnomalyDetection2019} is trained only on non-defective images. This works by encoding the images down to a smaller or compressed version of the original, and then expands it during the decoder portion.  The resultant image is then compared against the original and the defective regions detected via subtraction.  GAN's are another interesting and newly developed semi-supervised method.  Generative Adversarial Networks, which is essentially a two-player game between competing networks \cite{goodfellowGenerativeAdversarialNetworks2014a}.


%\subsection{Deep Learning}
%
%In the last decade Deep Neural Networks (DNN) have become increasingly popular as t
%
%Long-Short Term Memory (LSTM) Networks are another supervised deep learning method \cite{malhotraLSTMbasedEncoderDecoderMultisensor2016} 
%\cite{ruffUnifyingReviewDeep2020}
%
%\cite{raissiHiddenPhysicsModels2018}

\subsection{Anomaly Detection in meteorology}

\subsection{Overview}

Over all, the use of machine learning and artificial intelligence in anomaly detection has advanced greatly in the last decade, especially in the area of process controls in manufacturing \cite{venkatasubramanianReviewProcessFault2003}.  In the area of weather monitoring and sensor detection we have started to see some research in this area, such as with the work by \citet{onalWeatherDataAnalysis2017a}.  However these methods still focus on unsupervised clustering algorithms such as k-nearest neighbors and other statistical techniques.
